# VISHOD - Visual Dataset Scraping and Hybrid Outlier Detection

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.6.0-orange.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## ğŸ“‹ Sobre o Projeto

**VISHOD** (Visual Dataset Scraping and Hybrid Outlier Detection) Ã© um mÃ©todo automatizado para construÃ§Ã£o e refinamento de datasets de imagens utilizando web scraping e uma abordagem hÃ­brida de detecÃ§Ã£o de outliers. Este projeto foi desenvolvido como parte de uma pesquisa encabeÃ§ada pelo Prof. Seruffo e o Orientando FLÃ¡vio Moura, focando na criaÃ§Ã£o de datasets de alta qualidade para aplicaÃ§Ãµes de aprendizado supervisionado, especialmente em contextos com recursos computacionais limitados.

### ğŸ¯ Objetivo

O projeto visa resolver o desafio de construir datasets extensos e precisamente rotulados de forma automatizada, sem necessidade de anotaÃ§Ã£o manual. Como estudo de caso, desenvolvemos um classificador leve de imagens para reconhecimento de formas geomÃ©tricas bidimensionais comuns, destinado a apoiar aplicaÃ§Ãµes educacionais em contextos com conectividade limitada, como a regiÃ£o amazÃ´nica.

### ğŸ“Š Resultados Principais

Os resultados demonstram que o mÃ©todo permite a construÃ§Ã£o de datasets balanceados e de alta qualidade, com melhorias significativas apÃ³s o processo de limpeza:

- **+25.6%** de aumento na variÃ¢ncia mÃ©dia do PCA (maior diversidade)
- **-5.6%** de reduÃ§Ã£o na distÃ¢ncia mÃ©dia ao centrÃ³ide (maior coesÃ£o)
- **+21.6%** de aumento no Ã­ndice de similaridade estrutural mÃ©dio (SSIM) (maior homogeneidade visual)

## ğŸ—ï¸ Arquitetura do Sistema

O pipeline proposto compreende quatro estÃ¡gios principais:

### 1. Coleta Automatizada de Imagens (Web Scraping)
- ExtraÃ§Ã£o sistemÃ¡tica de imagens de fontes online
- Uso de termos combinados (descritores visuais e modificadores contextuais) para consultas em mecanismos de busca
- ParalelizaÃ§Ã£o do processo de coleta para eficiÃªncia

### 2. ExtraÃ§Ã£o de RepresentaÃ§Ãµes SemÃ¢nticas
- UtilizaÃ§Ã£o de modelos de deep learning prÃ©-treinados (ResNet-50) para extraÃ§Ã£o de features
- GeraÃ§Ã£o de representaÃ§Ãµes vetoriais de alta dimensÃ£o para anÃ¡lise posterior

### 3. DetecÃ§Ã£o e EliminaÃ§Ã£o de Outliers (Abordagem HÃ­brida)
- **HDBSCAN**: DetecÃ§Ã£o de outliers baseada em densidade hierÃ¡rquica
- **Isolation Forest**: IdentificaÃ§Ã£o de anomalias atravÃ©s de isolamento
- **DistÃ¢ncia de Mahalanobis**: DetecÃ§Ã£o de instÃ¢ncias estatisticamente discrepantes
- Abordagem de consenso para identificaÃ§Ã£o robusta de outliers

### 4. ValidaÃ§Ã£o do Dataset
- InspeÃ§Ã£o visual automatizada
- AnÃ¡lise estatÃ­stica de performance
- MÃ©tricas de qualidade: PCA, DistÃ¢ncia Euclidiana e SSIM

## ğŸ“ Estrutura do Projeto

```
WildShapesDB/
â”œâ”€â”€ collector/          # MÃ³dulo de coleta de imagens via web scraping
â”‚   â”œâ”€â”€ scrapper.py    # ImplementaÃ§Ã£o do scraper
â”‚   â””â”€â”€ utils.py       # UtilitÃ¡rios para geraÃ§Ã£o de queries
â”œâ”€â”€ cleaner/           # MÃ³dulo de detecÃ§Ã£o e remoÃ§Ã£o de outliers
â”‚   â”œâ”€â”€ feature_extractor.py    # ExtraÃ§Ã£o de features usando deep learning
â”‚   â”œâ”€â”€ hdbscan.py              # DetecÃ§Ã£o de outliers com HDBSCAN
â”‚   â”œâ”€â”€ isolation_forest.py    # DetecÃ§Ã£o de outliers com Isolation Forest
â”‚   â””â”€â”€ hnsw_index.py          # IndexaÃ§Ã£o eficiente com FAISS HNSW
â”œâ”€â”€ evaluator/         # MÃ³dulo de avaliaÃ§Ã£o de qualidade do dataset
â”‚   â”œâ”€â”€ analyze.py     # AnÃ¡lise estatÃ­stica do dataset
â”‚   â”œâ”€â”€ metrics.py     # ImplementaÃ§Ã£o de mÃ©tricas (PCA, SSIM, etc.)
â”‚   â””â”€â”€ healthcheck.py # VerificaÃ§Ã£o de integridade das imagens
â”œâ”€â”€ classifier/        # MÃ³dulo de classificaÃ§Ã£o
â”‚   â”œâ”€â”€ model.py       # Arquitetura do modelo (EfficientNet-B0 + Feature Fusion)
â”‚   â”œâ”€â”€ training.py    # Script de treinamento
â”‚   â”œâ”€â”€ evaluate.py    # Script de avaliaÃ§Ã£o
â”‚   â”œâ”€â”€ optimize.py    # OtimizaÃ§Ã£o de hiperparÃ¢metros com Optuna
â”‚   â””â”€â”€ data.py        # PreparaÃ§Ã£o e divisÃ£o dos dados
â”œâ”€â”€ gen_dataset.py     # Script principal para geraÃ§Ã£o do dataset
â”œâ”€â”€ clean_dataset.py   # Script principal para limpeza do dataset
â”œâ”€â”€ train_model.py     # Script principal para treinamento do modelo
â”œâ”€â”€ optimize_model.py  # Script principal para otimizaÃ§Ã£o de hiperparÃ¢metros
â”œâ”€â”€ test.py            # Script de teste do modelo
â””â”€â”€ search_query_data.json  # Dados de queries de busca por classe
```

## ğŸš€ InstalaÃ§Ã£o

### PrÃ©-requisitos

- Python 3.8 ou superior
- pip ou conda

### InstalaÃ§Ã£o das DependÃªncias

```bash
pip install -r requirements.txt
```

### Principais DependÃªncias

- **PyTorch 2.6.0**: Framework de deep learning
- **torchvision 0.21.0**: Modelos prÃ©-treinados e transformaÃ§Ãµes
- **scikit-learn 1.6.1**: Algoritmos de machine learning
- **hdbscan 0.8.40**: Clustering hierÃ¡rquico baseado em densidade
- **faiss-cpu 1.10.0**: Biblioteca de busca vetorial eficiente
- **selenium 4.28.1**: AutomaÃ§Ã£o de navegador para web scraping
- **opencv-python 4.11.0.86**: Processamento de imagens
- **matplotlib 3.10.0**: VisualizaÃ§Ã£o de dados
- **pandas 2.2.3**: ManipulaÃ§Ã£o de dados
- **optuna**: OtimizaÃ§Ã£o de hiperparÃ¢metros

## ğŸ’» Uso

### 1. GeraÃ§Ã£o do Dataset

Execute o script para coletar imagens automaticamente:

```bash
python gen_dataset.py
```

Este script:
- Carrega as queries de busca do arquivo `search_query_data.json`
- Gera consultas combinadas usando adjetivos, classes e substantivos
- Executa o web scraping em paralelo para coletar imagens
- Organiza as imagens por classe geomÃ©trica

### 2. Limpeza do Dataset

Execute o script para detectar e remover outliers:

```bash
python clean_dataset.py
```

Este script:
- Extrai features das imagens usando ResNet-50
- Aplica trÃªs mÃ©todos de detecÃ§Ã£o de outliers (HDBSCAN, Isolation Forest, Mahalanobis)
- Remove outliers identificados por consenso
- Gera visualizaÃ§Ãµes e anÃ¡lises estatÃ­sticas
- Avalia a qualidade do dataset antes e depois da limpeza

### 3. Treinamento do Modelo

Treine o classificador de formas geomÃ©tricas:

```bash
python train_model.py
```

O modelo utiliza:
- **EfficientNet-B0** como backbone (prÃ©-treinado no ImageNet)
- **Feature Fusion** combinando features do backbone com features de bordas
- **ECA (Efficient Channel Attention)** para atenÃ§Ã£o nas features
- **Early stopping** e **checkpointing** para melhor modelo

### 4. OtimizaÃ§Ã£o de HiperparÃ¢metros

Otimize os hiperparÃ¢metros do modelo usando Optuna:

```bash
python optimize_model.py
```

Este script:
- Executa 100 trials de otimizaÃ§Ã£o
- Explora espaÃ§o de hiperparÃ¢metros (learning rate, batch size, dropout, etc.)
- Salva os melhores hiperparÃ¢metros encontrados
- Gera visualizaÃ§Ãµes do processo de otimizaÃ§Ã£o

### 5. AvaliaÃ§Ã£o do Modelo

Teste o modelo treinado:

```bash
python test.py
```

## ğŸ§ª Modelo de ClassificaÃ§Ã£o

### Arquitetura

O classificador utiliza uma arquitetura hÃ­brida:

1. **Backbone**: EfficientNet-B0 (prÃ©-treinado, camadas iniciais congeladas)
2. **Extrator de Features de Bordas**: CNN leve para capturar caracterÃ­sticas geomÃ©tricas
3. **Feature Fusion**: CombinaÃ§Ã£o de features do backbone e de bordas usando ECA
4. **Classificador**: MLP com BatchNorm e Dropout

### Classes Suportadas

O modelo classifica as seguintes **9 formas geomÃ©tricas 2D**:
- CÃ­rculo (Circle)
- Elipse (Ellipse)
- HexÃ¡gono (Hexagon)
- Paralelogramo (Parallelogram)
- PentÃ¡gono (Pentagon)
- RetÃ¢ngulo (Rectangle)
- Quadrado (Square)
- TrapÃ©zio (Trapezoid)
- TriÃ¢ngulo (Triangle)

## ğŸ“ˆ MÃ©tricas de Qualidade do Dataset

O sistema avalia a qualidade do dataset usando trÃªs mÃ©tricas principais:

1. **VariÃ¢ncia do PCA**: Mede a diversidade dos dados no espaÃ§o de features
2. **DistÃ¢ncia Euclidiana ao CentrÃ³ide**: Mede a coesÃ£o e consistÃªncia dos dados
3. **SSIM (Structural Similarity Index)**: Mede a similaridade estrutural e homogeneidade visual

## ğŸ“Š VisualizaÃ§Ãµes

O projeto gera automaticamente visualizaÃ§Ãµes em `plots/`:

- AnÃ¡lises de clusters (HDBSCAN)
- DistribuiÃ§Ãµes de anomalias (Isolation Forest)
- DistribuiÃ§Ãµes de distÃ¢ncia de Mahalanobis
- AnÃ¡lises comparativas do dataset antes e depois da limpeza

## ğŸ“ AplicaÃ§Ã£o Educacional

Este projeto foi desenvolvido para suportar a aplicaÃ§Ã£o **GeoMeta**, um aplicativo mÃ³vel que auxilia no ensino de geometria atravÃ©s da classificaÃ§Ã£o de formas 2D. O modelo foi otimizado para:

- OperaÃ§Ã£o offline
- Compatibilidade com dispositivos de baixo desempenho
- Baixo consumo de recursos computacionais
- Alta precisÃ£o em reconhecimento de formas geomÃ©tricas

## ğŸ“ ConfiguraÃ§Ã£o

### Arquivo de Queries de Busca

O arquivo `search_query_data.json` contÃ©m as configuraÃ§Ãµes de busca para cada classe geomÃ©trica, incluindo:
- Objetos do cotidiano que representam cada forma
- Adjetivos descritivos
- Substantivos contextuais

### DivisÃ£o do Dataset

Os splits do dataset sÃ£o salvos em `dataset_splits/`:
- `train_indices.pt`: Ãndices de treinamento
- `val_indices.pt`: Ãndices de validaÃ§Ã£o
- `test_indices.pt`: Ãndices de teste

## ğŸ”¬ Metodologia de DetecÃ§Ã£o de Outliers

### Abordagem HÃ­brida de Consenso

O sistema utiliza trÃªs mÃ©todos complementares:

1. **HDBSCAN**: Identifica pontos que nÃ£o pertencem a clusters densos
2. **Isolation Forest**: Isola anomalias atravÃ©s de Ã¡rvores de decisÃ£o
3. **DistÃ¢ncia de Mahalanobis**: Detecta pontos estatisticamente distantes da distribuiÃ§Ã£o normal

Um ponto Ã© considerado outlier se identificado por pelo menos dois dos trÃªs mÃ©todos (consenso).

## ğŸ“š ReferÃªncias

Este projeto Ã© baseado na pesquisa:

**VISHOD - Visual Dataset Scraping and Hybrid Outlier Detection**

Autores: FlÃ¡vio Moura, Vitor Melo, AndrÃ© Alves, Lyanh Pinto, Walter JÃºnior, Adriano Santos, Roberto Oliveira, Jefferson Morais, Diego Cardoso, e Marcos Seruffo

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor:

1. FaÃ§a um fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ‘¥ Autores

- **FlÃ¡vio Moura**
- **Vitor Melo**
- **AndrÃ© Alves**
- **Lyanh Pinto**
- **Walter JÃºnior**
- **Adriano Santos**
- **Roberto Oliveira**
- **Jefferson Morais**
- **Diego Cardoso**
- **Marcos Seruffo**

## ğŸ™ Agradecimentos

Agradecemos a todos os colaboradores e Ã  comunidade de cÃ³digo aberto pelas ferramentas e bibliotecas que tornaram este projeto possÃ­vel.
